Our project targets the Enterprise Agents track, designing an AI-driven solution for a common business scenario: global product marketing and pricing under volatile currency conditions. In our fictional case, a multinational electronics firm struggles to set optimal prices for imported products. Rapid foreign exchange swings and a fragmented competitor landscape make manual analysis slow and error-prone. Decision-makers need concise, data-driven insights on market positioning, competitor pricing, and FX risk exposure. To meet this challenge, we built a multi-agent AI system that automates the full analysis pipeline. Given a product, region, and cost inputs, the system sequentially invokes specialized agents – each powered by Google’s Gemini LLM – to perform market research, competitive pricing analysis, FX-impact forecasting, margin scenario planning, and finally synthesize an executive brief. This solution mirrors how a team of human analysts would collaborate, but operates automatically and at high speed, yielding cost savings and timelier, more reliable decisions.

Our solution architecture is a tightly-coupled multi-agent pipeline with one coordinator agent orchestrating several specialist agents. The top-level Coordinator Agent receives a manager’s input (product, region, costs, optional target price/margin) and then calls downstream agents in order. First, a Market Research Agent uses an internal product database (via a custom “snapshot” tool) – and optionally web search – to summarize the market landscape: key competitors, typical brands, price bands, and product features. Next, a Competitive Pricing Agent fetches internal synthetic price data and optionally uses web context to build a structured view of competitor offers. It outputs a JSON table of competitor prices and computes a recommended competitive band. Then, the system gathers currency data via a Vendor FX Agent. This agent wraps a public FX API call (with fallback synthetic rates) and presents vendor-style exchange rates. The coordinator uses this to fix the current FX rate. With costs and FX rate in hand, the FX Impact Agent calculates multiple “what-if” scenarios: it calls an internal FX scenario tool to simulate ±5–10% currency moves, computes the resulting landed cost and margins, and produces both a narrative and structured JSON of these scenarios. Next, a Margin Scenario Planner Agent takes the baseline unit cost and candidate selling prices (including the user’s price and the competitor band) and uses internal tools to compute margins, compare to target margins, and propose strategic pricing anchors (e.g. “match market low”, “premia with differentiation”). It returns a JSON of margin scenarios and strategic recommendations. Finally, a Decision Brief Agent synthesizes all the collected data: it reads the JSON outputs from market research, competitive pricing, FX impact, and margin planning, and weaves them into a concise, business-friendly report. The Decision Brief includes an executive summary, key insights on competition and FX risk, and a clear price recommendation. To ensure quality, an Evaluation Agent then reviews the final brief and its structured summary for coverage, consistency, clarity, and actionability, returning feedback scores and improvement suggestions.

Throughout this pipeline, every agent is powered by the Gemini model. We used Google’s google-genai client to configure each agent with a Gemini variant (e.g. gemini-2.5-flash). For example, the Market Research and Competitive Pricing agents use Gemini to interpret the snapshot tool outputs and craft human-readable narratives, while the Decision Brief agent relies on Gemini to merge multiple inputs into a coherent report. This integration is central: Gemini’s language understanding enables each agent to handle complex instructions and JSON schema outputs, and its tool-calling support allows seamless invocation of our custom functions. We highlight this use of Gemini as a key project feature – it fulfills the bonus criterion “Effective Use of Gemini”. In practice, Gemini dramatically boosts performance by generating fluent natural language and structured JSON reliably, and by focusing reasoning on calling our deterministic tools for data retrieval. For instance, the Decision Brief agent used Gemini to cross-check numeric inputs (ensuring consistency with the JSON data) and to articulate the final recommendations, tasks that would be brittle with rule-based methods.

In accordance with the Capstone requirements, our solution demonstrates several key features. It is a multi-agent system with sequential agents; each agent is an LLM-based specialist, reflecting the “Agent powered by an LLM” and “Sequential agents” concepts. We treat the set of specialist agents (market research, pricing, FX, margin, briefing, evaluation) plus the top-level coordinator as a coherent team; their sequential chain ensures a controlled, explainable workflow. (We did not implement explicit parallel or loop agents in this version, since the natural business process is stepwise. However, our design could accommodate parallel runs of agents if scaled up.)

Our system heavily uses tools. Each specialist agent calls custom domain tools to produce stable, deterministic outputs that can be audited. For example, the product snapshot tool, competitor price snapshot tool, FX scenario calculator, and margin planning functions are all implemented as FunctionTools. These ensure that the agents’ reasoning rests on transparent data, and the agents can justify their outputs using the tool data. We also integrate an external data tool: the Vendor FX agent wraps a public JSON FX API (via the fawazahmed0/currency-api). This simulates real-world OpenAPI usage; the agent treats the tool response as authoritative “live” or “synthetic” rates. Collectively, these tools – domain-specific analytics, external data fetchers, and operational utilities – form a stable foundation for agent reasoning. As documented, we organize them into categories (domain, operational, monitoring) to keep the system debuggable and extensible.

We employ state management and memory via ADK’s session and memory services. Each run of the pipeline uses an InMemoryRunner session to track the conversation history. Key intermediate data (inputs, JSON outputs) persist within the session, allowing agents to reference past steps. For example, the Decision Brief agent reads the JSON results of upstream agents from the coordinator prompt. While we use only short-term in-memory context, we also implement context compaction: if a conversation grows too long, we summarize earlier exchanges and store a compact memory entry. This ensures the system remains efficient even for iterative or batch runs. (Our implementation includes a batch_query helper that summarizes and clears messages beyond a threshold.)

Observability is integrated throughout. We attach a logging plugin (InvocationCounterPlugin) to count how many times models, tools, and agents are invoked. Agents emit structured log events on resets or errors, and we track metrics (queries processed, avg. latency, etc.). Export functions dump conversation history and agent logs, which aids debugging and demonstration. In the coordinator’s final output, we include optional telemetry: counts of tool calls, memory usage, and raw conversation turns for auditing. This level of logging and metrics is crucial in an enterprise context to trust and refine the system.

Our project also showcases agent evaluation and agent-to-agent (A2A) features. The built-in Evaluation Agent systematically reviews the final decision brief against its structured JSON, scoring coverage and consistency. This “second pair of eyes” agent helps catch any logical gaps automatically and provides feedback, which is valuable for quality control. For A2A, we created a standalone FX microservice (using ADK’s to_a2a framework) that simulates a remote vendor FX provider. We then defined a RemoteA2aAgent client that calls this service. In practice, the Coordinator could call this remote agent in place of the local vendor FX tool. We include a demo block that invokes the remote agent with a structured request (base/quote currencies and horizon) and receives a JSON with synthetic FX spot and scenarios. This illustrates how an independently deployed agent or API can be seamlessly integrated, fulfilling the “A2A Protocol” feature. All toolkit elements – from tools to memory to observability – are thus essential: they enable our agents to function correctly, reliably, and verifiably.

Implementation journey: Initially, we defined the business scenario (FX-aware pricing) to align with the Enterprise track, then sketched a linear pipeline of analysis steps. Our first prototype was a single agent that tried to do everything, which led to poor focus and messy prompts. We quickly refactored into specialist agents, each with a narrow domain. Defining clear JSON schemas in the instructions was crucial for structured outputs. A major challenge was keeping the system deterministic for testing and grading. We solved this by using seeded randomness (_make_rng) in all synthetic generators, so repeated runs with the same input produce the same outputs. We also encountered token overflow issues when feeding large JSON into the Decision agent; to address this, we enforced concise JSON writing and tested truncation. Iteratively, we added the Evaluation agent to check our own work and noticed areas where prompts needed clarification. Another obstacle was managing the complex orchestration in code; building a helper to assemble the coordinator’s prompt ensured consistency and simplified maintenance. Along the way, we handled environment issues (resolving package conflicts during pip install), but the main focus was on designing robust instructions and data flows.

In summary, our FX-Aware Pricing Agent system delivers substantial value. It automates a multi-step analytic process that would otherwise take human analysts hours to complete, reducing time-to-insight dramatically. By surfacing competitor intel, currency risk, and margin strategies in a single integrated report, it empowers business managers with actionable intelligence. All components – agents, tools, memory and observability – are woven together to ensure the solution is not just a black-box: every decision is traceable to underlying data and logic. This architecture exemplifies the Enterprise Agents vision by improving a key business workflow through AI-driven automation.

Sources: Kaggle Capstone documentation and our project code were the basis for this design. The official feature checklist guided our implementation, and code excerpts (e.g. agent definitions and orchestrator logic) confirm the described roles and flow. These references ensure alignment between our writeup and the actual implementation.